"""Tests for exploitability calculation."""

import numpy as np
from aion26.metrics.exploitability import (
    compute_exploitability,
    compute_nash_conv,
    best_response_value,
    evaluate_strategy_profile,
)
from aion26.games.kuhn import new_kuhn_game
from aion26.cfr.vanilla import VanillaCFR


class TestBestResponseValue:
    """Test best response value computation."""

    def test_best_response_against_always_check(self):
        """Test best response against opponent who always checks."""
        game = new_kuhn_game()

        # Opponent always checks
        opponent_strategy = {
            "J": np.array([1.0, 0.0]),  # Check
            "Q": np.array([1.0, 0.0]),  # Check
            "K": np.array([1.0, 0.0]),  # Check
            "Jc": np.array([1.0, 0.0]),  # Check (after opponent checked)
            "Qc": np.array([1.0, 0.0]),
            "Kc": np.array([1.0, 0.0]),
            "Jb": np.array([1.0, 0.0]),  # Fold (facing a bet)
            "Qb": np.array([1.0, 0.0]),
            "Kb": np.array([1.0, 0.0]),
            "Jcb": np.array([1.0, 0.0]),  # Fold (facing a bet after checking)
            "Qcb": np.array([1.0, 0.0]),
            "Kcb": np.array([1.0, 0.0]),
        }

        # Against an opponent who always checks/folds, we should be able to win easily
        br_value = best_response_value(game, best_responder=0, opponent_strategy=opponent_strategy)
        # We should be able to get positive expected value
        assert br_value > 0

    def test_best_response_against_always_bet(self):
        """Test best response against opponent who always bets."""
        game = new_kuhn_game()

        # Opponent always bets/calls
        opponent_strategy = {
            "J": np.array([0.0, 1.0]),  # Bet
            "Q": np.array([0.0, 1.0]),  # Bet
            "K": np.array([0.0, 1.0]),  # Bet
            "Jc": np.array([0.0, 1.0]),  # Bet (after opponent checked)
            "Qc": np.array([0.0, 1.0]),
            "Kc": np.array([0.0, 1.0]),
            "Jb": np.array([0.0, 1.0]),  # Call (facing a bet)
            "Qb": np.array([0.0, 1.0]),
            "Kb": np.array([0.0, 1.0]),
            "Jcb": np.array([0.0, 1.0]),  # Call (facing a bet after checking)
            "Qcb": np.array([0.0, 1.0]),
            "Kcb": np.array([0.0, 1.0]),
        }

        # Against an opponent who always bets/calls, best response should exploit this
        br_value = best_response_value(game, best_responder=0, opponent_strategy=opponent_strategy)
        # Value could be positive or negative depending on the game structure
        assert isinstance(br_value, float)


class TestExploitability:
    """Test exploitability computation."""

    def test_uniform_strategy_is_exploitable(self):
        """Test that uniform random strategy is highly exploitable."""
        game = new_kuhn_game()

        # Uniform strategy (50-50 for all actions)
        uniform_strategy = {
            "J": np.array([0.5, 0.5]),
            "Q": np.array([0.5, 0.5]),
            "K": np.array([0.5, 0.5]),
            "Jc": np.array([0.5, 0.5]),
            "Qc": np.array([0.5, 0.5]),
            "Kc": np.array([0.5, 0.5]),
            "Jb": np.array([0.5, 0.5]),
            "Qb": np.array([0.5, 0.5]),
            "Kb": np.array([0.5, 0.5]),
            "Jcb": np.array([0.5, 0.5]),
            "Qcb": np.array([0.5, 0.5]),
            "Kcb": np.array([0.5, 0.5]),
        }

        exploitability = compute_exploitability(game, uniform_strategy)
        # Uniform strategy should be exploitable (empirically around 1.0 for Kuhn)
        assert exploitability > 0.5
        assert exploitability < 1.5  # Sanity check

    def test_exploitability_is_non_negative(self):
        """Test that exploitability is always non-negative."""
        game = new_kuhn_game()

        # Create some arbitrary strategy
        strategy = {
            "J": np.array([0.7, 0.3]),
            "Q": np.array([0.6, 0.4]),
            "K": np.array([0.2, 0.8]),
            "Jc": np.array([0.5, 0.5]),
            "Qc": np.array([0.5, 0.5]),
            "Kc": np.array([0.5, 0.5]),
            "Jb": np.array([0.9, 0.1]),  # Jack folds most of the time
            "Qb": np.array([0.5, 0.5]),
            "Kb": np.array([0.1, 0.9]),  # King calls most of the time
            "Jcb": np.array([0.8, 0.2]),
            "Qcb": np.array([0.5, 0.5]),
            "Kcb": np.array([0.2, 0.8]),
        }

        exploitability = compute_exploitability(game, strategy)
        # Exploitability should always be non-negative
        assert exploitability >= -1e-10  # Allow for small numerical errors

    def test_nash_conv_equals_exploitability(self):
        """Test that NashConv is just another name for exploitability."""
        game = new_kuhn_game()

        strategy = {
            "J": np.array([0.5, 0.5]),
            "Q": np.array([0.5, 0.5]),
            "K": np.array([0.5, 0.5]),
            "Jc": np.array([0.5, 0.5]),
            "Qc": np.array([0.5, 0.5]),
            "Kc": np.array([0.5, 0.5]),
            "Jb": np.array([0.5, 0.5]),
            "Qb": np.array([0.5, 0.5]),
            "Kb": np.array([0.5, 0.5]),
            "Jcb": np.array([0.5, 0.5]),
            "Qcb": np.array([0.5, 0.5]),
            "Kcb": np.array([0.5, 0.5]),
        }

        exploitability = compute_exploitability(game, strategy)
        nash_conv = compute_nash_conv(game, strategy)
        assert abs(exploitability - nash_conv) < 1e-10


class TestEvaluateStrategyProfile:
    """Test strategy profile evaluation."""

    def test_evaluate_strategy_profile_keys(self):
        """Test that evaluate_strategy_profile returns expected keys."""
        game = new_kuhn_game()

        strategy = {
            f"{card}{history}": np.array([0.5, 0.5])
            for card in ["J", "Q", "K"]
            for history in ["", "c", "b", "cb"]
        }

        metrics = evaluate_strategy_profile(game, strategy)
        assert "exploitability" in metrics
        assert "best_response_value_p0" in metrics
        assert "best_response_value_p1" in metrics

    def test_evaluate_strategy_zero_sum_property(self):
        """Test that best response values approximately sum to exploitability.

        For a two-player zero-sum game, the sum of BR values equals exploitability.
        """
        game = new_kuhn_game()

        strategy = {
            f"{card}{history}": np.array([0.5, 0.5])
            for card in ["J", "Q", "K"]
            for history in ["", "c", "b", "cb"]
        }

        metrics = evaluate_strategy_profile(game, strategy)
        br_sum = metrics["best_response_value_p0"] + metrics["best_response_value_p1"]
        exploitability = metrics["exploitability"]

        # Should be equal (allowing for numerical error)
        assert abs(br_sum - exploitability) < 1e-10


class TestCFRConvergenceExploitability:
    """Test that CFR reduces exploitability over time."""

    def test_cfr_reduces_exploitability(self):
        """Test that running CFR reduces exploitability."""
        game = new_kuhn_game()
        solver = VanillaCFR(game, seed=42)

        # Run a few iterations
        for _ in range(100):
            solver.run_iteration()

        early_strategy = solver.get_all_average_strategies()
        early_exploit = compute_exploitability(game, early_strategy)

        # Run many more iterations
        for _ in range(10000):
            solver.run_iteration()

        late_strategy = solver.get_all_average_strategies()
        late_exploit = compute_exploitability(game, late_strategy)

        # Exploitability should decrease (or at least not increase significantly)
        # With outcome sampling, there's variance, so we use a loose bound
        assert late_exploit < early_exploit * 1.5  # Allow some noise

    def test_cfr_exploitability_trend(self):
        """Test that exploitability generally trends downward."""
        game = new_kuhn_game()
        solver = VanillaCFR(game, seed=42)

        exploitabilities = []

        # Measure exploitability at several checkpoints
        checkpoints = [100, 500, 1000, 5000, 10000]
        for checkpoint in checkpoints:
            # Run to checkpoint
            while solver.iteration < checkpoint:
                solver.run_iteration()

            strategy = solver.get_all_average_strategies()
            exploit = compute_exploitability(game, strategy)
            exploitabilities.append(exploit)

        # Early exploitability should generally be higher than late
        # (allowing for variance from sampling)
        assert exploitabilities[0] > exploitabilities[-1] * 0.5
